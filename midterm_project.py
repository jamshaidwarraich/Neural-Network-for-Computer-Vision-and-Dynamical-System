# -*- coding: utf-8 -*-
"""Midterm project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/107_dkO2DeK9RpqiqoGoQyT6M-A44Pyen
"""

#importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.datasets import cifar10

#class of neural network
class neural_network:
    def __init__(self, inodes, h1nodes, h2nodes, onodes, learningrate):
        self.inputnodes = inodes
        self.hidden1nodes = h1nodes
        self.hidden2nodes = h2nodes
        self.outputnodes = onodes
        self.learning = learningrate
        self.wih1 = np.random.normal(0.0, pow(self.hidden1nodes, -0.5), (self.hidden1nodes, self.inputnodes))
        self.wh1h2 = np.random.normal(0.0, pow(self.hidden2nodes, -0.5), (self.hidden2nodes, self.hidden1nodes))
        self.h2o = np.random.normal(0.0, pow(self.outputnodes, -0.5), (self.outputnodes, self.hidden2nodes))
#defining the activation functions
    def relu(self, x):
        return np.maximum(0, x)

    def relu_derivative(self, x):
        return np.where(x > 0, 1, 0)

    def softmax(self, z):
        exp_z = np.exp(z)
        return exp_z / np.sum(exp_z)

    def softmax_derivative(self, z):
        s = self.softmax(z)
        return s * (1 - s)
#defining the training paramerts
    def train(self, inputs, targets):
        inputs = np.array(inputs, ndmin=2).T
        targets = np.array(targets, ndmin=2).T

        hidden1_inputs = np.dot(self.wih1, inputs)
        hidden1_outputs = self.relu(hidden1_inputs)

        hidden2_inputs = np.dot(self.wh1h2, hidden1_outputs)
        hidden2_outputs = self.relu(hidden2_inputs)

        final_inputs = np.dot(self.h2o, hidden2_outputs)
        final_outputs = self.softmax(final_inputs)

        output_errors = targets - final_outputs
        hidden2_errors = np.dot(self.h2o.T, output_errors)
        hidden1_errors = np.dot(self.wh1h2.T, hidden2_errors)

        #updating the weights
        self.h2o += self.learning * np.dot((output_errors * self.relu_derivative(final_outputs)),
                                           np.transpose(hidden2_outputs))
        self.wh1h2 += self.learning * np.dot((hidden2_errors * self.relu_derivative(hidden2_outputs)),
                                              np.transpose(hidden1_outputs))
        self.wih1 += self.learning * np.dot((hidden1_errors * self.relu_derivative(hidden1_outputs)),
                                             np.transpose(inputs))
#defining the query
    def query(self, user_input):
        inputs = np.array(user_input, ndmin=2).T
        hidden1_inputs = np.dot(self.wih1, inputs)
        hidden1_outputs = self.relu(hidden1_inputs)

        hidden2_inputs = np.dot(self.wh1h2, hidden1_outputs)
        hidden2_outputs = self.relu(hidden2_inputs)

        final_inputs = np.dot(self.h2o, hidden2_outputs)
        final_outputs = self.softmax(final_inputs)

        return final_outputs

# Load CIFAR-10 data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Network parameters
inodes = 3072
h1nodes = 1000
h2nodes = 1000
onodes = 10
learningrate = 0.3

# Initialize NN
NN = neural_network(inodes, h1nodes, h2nodes, onodes, learningrate)

# Training
for record in range(len(x_train)):
    inputs = (np.asfarray(x_train[record].flatten()) / 255.0 * 0.99) + 0.01
    targets = np.zeros(onodes) + 0.01
    targets[y_train[record]] = 0.99
    NN.train(inputs, targets)

# Testing
epochs = 2
scorecard = []

for epoch in range(epochs):
    for record in range(len(x_test)):
        test_inputs = (np.asfarray(x_test[record].flatten()) / 255.0 * 0.99) + 0.01
        target_label = int(y_test[record])
        outputs = NN.query(test_inputs)
        NN_label = np.argmax(outputs)
        if NN_label == target_label:
            scorecard.append(1)
        else:
            scorecard.append(0)  # Append 0 for incorrect classification
    print("scorecard:", scorecard)
    accuracy = sum(scorecard) / len(scorecard)
    print(f"Epoch {epoch+1}, Accuracy: {accuracy}")

print("Testing completed.")

total_images_in_test_set = len(x_test)
print("Total number of images in the test set:", total_images_in_test_set)
total_images_in_training_set = len(x_train)
print("Total number of images in traing set:", total_images_in_training_set)

lentrain= len(y_train)
print("Total training labels are",lentrain)
lentest= len(y_test)
print("Total testing labels are",lentest)

#displaying results at particular index
import matplotlib.pyplot as plt

test_index = 3  # Choose the index of the test sample you want to visualize
test_image = x_test[test_index]
true_image = x_train[test_index]
true_label = y_test[test_index][0]  # Assuming y_test is not one-hot encoded

# Query the neural network to get the output
output_probs = NN.query(test_image.flatten())
predicted_label = np.argmax(output_probs)

categories = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
predicted_category = categories[predicted_label]
true_category = categories[true_label]

print("True label:", true_label)
print("Predicted label:", predicted_label)
print("True category:", true_category)
print("Predicted category:", predicted_category)

#importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.datasets import cifar10

#class of neural network
class neural_network:
    def __init__(self, inodes, h1nodes, h2nodes, onodes, learningrate):
        self.inputnodes = inodes
        self.hidden1nodes = h1nodes
        self.hidden2nodes = h2nodes
        self.outputnodes = onodes
        self.learning = learningrate
        self.wih1 = np.random.normal(0.0, pow(self.hidden1nodes, -0.5), (self.hidden1nodes, self.inputnodes))
        self.wh1h2 = np.random.normal(0.0, pow(self.hidden2nodes, -0.5), (self.hidden2nodes, self.hidden1nodes))
        self.h2o = np.random.normal(0.0, pow(self.outputnodes, -0.5), (self.outputnodes, self.hidden2nodes))

    def relu(self, x):
        return np.maximum(0, x)

    def relu_derivative(self, x):
        return np.where(x > 0, 1, 0)

    def softmax(self, z):
        exp_z = np.exp(z)
        return exp_z / np.sum(exp_z)

    def softmax_derivative(self, z):
        s = self.softmax(z)
        return s * (1 - s)

    def train(self, inputs, targets):
        inputs = np.array(inputs, ndmin=2).T
        targets = np.array(targets, ndmin=2).T

        hidden1_inputs = np.dot(self.wih1, inputs)
        hidden1_outputs = self.relu(hidden1_inputs)

        hidden2_inputs = np.dot(self.wh1h2, hidden1_outputs)
        hidden2_outputs = self.relu(hidden2_inputs)

        final_inputs = np.dot(self.h2o, hidden2_outputs)
        final_outputs = self.softmax(final_inputs)

        output_errors = targets - final_outputs
        hidden2_errors = np.dot(self.h2o.T, output_errors)
        hidden1_errors = np.dot(self.wh1h2.T, hidden2_errors)

        #updating the weights
        self.h2o += self.learning * np.dot((output_errors * self.relu_derivative(final_outputs)),
                                           np.transpose(hidden2_outputs))
        self.wh1h2 += self.learning * np.dot((hidden2_errors * self.relu_derivative(hidden2_outputs)),
                                              np.transpose(hidden1_outputs))
        self.wih1 += self.learning * np.dot((hidden1_errors * self.relu_derivative(hidden1_outputs)),
                                             np.transpose(inputs))

    def query(self, user_input):
        inputs = np.array(user_input, ndmin=2).T
        hidden1_inputs = np.dot(self.wih1, inputs)
        hidden1_outputs = self.relu(hidden1_inputs)

        hidden2_inputs = np.dot(self.wh1h2, hidden1_outputs)
        hidden2_outputs = self.relu(hidden2_inputs)

        final_inputs = np.dot(self.h2o, hidden2_outputs)
        final_outputs = self.softmax(final_inputs)

        return final_outputs

# Load CIFAR-10 data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Network parameters
inodes = 3072
h1nodes = 10
h2nodes = 10
onodes = 10
learningrate = 0.01

# Initialize NN
NN = neural_network(inodes, h1nodes, h2nodes, onodes, learningrate)

# Training
for record in range(len(x_train)):
    inputs = (np.asfarray(x_train[record].flatten()) / 255.0 * 0.99) + 0.01
    targets = np.zeros(onodes) + 0.01
    targets[y_train[record]] = 0.99
    NN.train(inputs, targets)

# Testing
epochs = 5
scorecard = []

for epoch in range(epochs):
    for record in range(len(x_test)):
        test_inputs = (np.asfarray(x_test[record].flatten()) / 255.0 * 0.99) + 0.01
        target_label = int(y_test[record])
        outputs = NN.query(test_inputs)
        NN_label = np.argmax(outputs)
        if NN_label == target_label:
            scorecard.append(1)
        else:
            scorecard.append(0)  # Append 0 for incorrect classification
    print("scorecard:", scorecard)
    accuracy = sum(scorecard) / len(scorecard)
    print(f"Epoch {epoch+1}, Accuracy: {accuracy}")

print("Testing completed.")